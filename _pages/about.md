---
permalink: /
title: "Ronghui Li(ÊùéÈïïËæâ)"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a second-year Ph.D. student at Shenzhen International Graduate School, Tsinghua University supervised by Prof. Xiu Li. 
Prior to that, I received my M.Eng. from Northeastern University (China) under the supervision of Assoc. Prof. Lu Meng. 

Now, I'm passion about human-centric topics, including <strong>character animation, motion recognition, 3D vison, and Generative Model</strong>. 



_______________________________________________________________________________________________________
<h3>
  <a name="news"></a> üÜïNews
</h3>
<div class="mini">
  <ul>
  <li> <strong>[Dec 2023]</strong> Two papers about controllable human generation and controllable dance generation are accepted by ICASSP 2024!</li>
  <li> <strong>[Dec 2023]</strong> Two papers about 3D object grounding and gestures generation are accepted by AAAI 2024!</li>
  <li> <strong>[Jul 2023]</strong> One papers about Music driven dance generation accepted by ICCV 2023!</li>
  </ul>
</div>

<style>
table, th, td {
  border: none;
  border-collapse: collapse;
}
</style>


_______________________________________________________________________________________________________

<h3>
  <a name="Publications"></a> ‚ú®Selected Publications
</h3>

<font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="0" cellpadding="0" class="noBorder">
           <tbody>
                <tr>
                    <td width="40%">
                        <img width="320" src="../images/DanceControl.jpg" border="0">
                            </td>
                    <td>
                            <b>Exploring Multi-Modal Control in Music-Driven Dance Generation</b>
                    <br>
                    <strong>Ronghui Li</strong>, Yuqin Dai, Yachao Zhang, Jun Li, Jian Yang, Jie Guo, Xiu Li.
                    <br>
                    <em>IEEE International Conference on Acoustics, Speech and Signal Processing
 (ICASSP 2024)</em>
                    <br>
                    [<a href="https://arxiv.org/abs/2401.01382">Paper</a>]
                    </td>
                </tr>
                <tr>
                    <td width="40%">
                        <img width="320" src="../images/Text2Avatar.jpg" border="0">
                            </td>
                    <td>
                          <b>Text2Avatar: Text to 3D Human Avatar Generation with Codebook-Driven Body Controllable Attribute</b>
                    <br>
                    Chaoqun Gong, Yuqin Dai, <strong>Ronghui Li</strong>, Achun Bao, Jun Li, Jian Yang, Yachao Zhang, Xiu Li.
                    <br>
                    <em>IEEE International Conference on Acoustics, Speech and Signal Processing
 (ICASSP 2024)</em>
                    <br>
                    [<a href="https://browse.arxiv.org/abs/2401.00711">Paper</a>]
                    </td>
                </tr>
                <tr>
                    <td width="40%">
                        <img width="320" src="../images/FineDance.gif" border="0">
                            </td>
                    <td>
                            <b>FineDance: A Fine-grained Choreography Dataset for 3D Full Body Dance Generation</b>
                    <br>
                    <strong>Ronghui Li</strong>, Junfan Zhao,  Yachao Zhang, Mingyang Su, Zeping Ren, Han Zhang, Yansong Tang, Xiu Li.
                    <br>
                    <em>IEEE Conference on International Conference on Computer Vision (ICCV 2023)</em>
                    <br>
                    [<a href="https://li-ronghui.github.io/finedance">Project</a>][<a href="https://arxiv.org/abs/2312.15900">Paper</a>][<a href="https://github.com/li-ronghui/FineDance">Code</a>]
                    </td>
                </tr>
                <tr>
                    <td width="40%">
                        <img width="320" src="../images/xmatch.jpg" border="0">
                            </td>
                    <td>
                            <b>Cross-Modal Match for Language Conditioned 3D Object Grounding</b>
                    <br>
                    Yachao Zhang, Runze Hu, <strong>Ronghui Li</strong>, Yanyun Qu, Yuan Xie, Xiu Li.
                    <br>
                    <em>Association for the Advance of Artificial Intelligence (AAAI 2024)</em>
                    <br>
                    [<a> Paper</a>][<a href="https://github.com/li-ronghui">Code coming soon!</a>]
                    </td>
                </tr>
               <tr>
                    <td width="40%">
                        <img width="320" src="../images/gesture.jpg" border="0">
                            </td>
                    <td>
                            <b>Chain of Generation: Multi-Modal Gesture Synthesis via Cascaded Conditional Control</b>
                    <br>
                     Zunnan XuÔºåYachao ZhangÔºåSicheng YangÔºå<strong>Ronghui Li</strong>ÔºåXiu Li.
                    <br>
                    <em>Association for the Advance of Artificial Intelligence (AAAI 2024)</em>
                    <br>
                   [<a href="https://arxiv.org/abs/2312.15900">Paper</a>][<a href="https://github.com/li-ronghui">Code coming soon!</a>]
                    </td>
               </tr>
                    </tbody>
           </table>
</font>


[Please visit [my google scholar profile](https://scholar.google.com/citations?hl=en&user=h1PooycAAAAJ) for the full publication list.]

_______________________________________________________________________________________________________

<h3>
  <a name="services"></a> üö©Academic Services
</h3>
<div class="mini">
  <ul>
  <li> <strong>Emergency Conference Reviewer</strong>: CVPR </li>
  <li> <strong>Journal Reviewer</strong>: International Journal of Human-Computer Interaction (IJHCI)</li>
  </ul>
</div>